#  形態素解析関数
def word_tokenize(x):
    text = neologd_tagger.parse(x)
    lines = text.split('\n')
    words = []
    for line in lines:
        cols = line.split("\t")
        if cols[0] != 'EOS':
            words.append( cols[0] )
    return words
